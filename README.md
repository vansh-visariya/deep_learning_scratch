# ğŸ§  Deep Learning from Scratch

> *"Understanding is a three-edged sword: your side, their side, and the truth."* - Building neural networks from first principles to truly understand the magic behind deep learning.

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
[![NumPy](https://img.shields.io/badge/NumPy-Latest-orange.svg)](https://numpy.org)

## ğŸ¯ Project Overview

This project implements a complete deep learning framework from scratch using only NumPy, providing crystal-clear insights into the mathematical foundations of neural networks. Every component is built ground-up to demystify the "black box" of deep learning.

## ğŸ“ Project Structure

```
dl-from-scratch/
â”œâ”€â”€ layer/
â”‚   â”œâ”€â”€ connect_layers.py    # Dense layer implementation
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ multi_activation/
â”‚   â”œâ”€â”€ activation.py        # ReLU, Sigmoid, Softmax functions
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ losses/
â”‚   â”œâ”€â”€ loss.py             # Cross-entropy loss functions
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ main_model.py       # Model class and SGD optimizer
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ basic_dl.ipynb         # Basic implementation examples
â”œâ”€â”€ connected.ipynb        # Connected layers examples
â””â”€â”€ README.md
```

## ğŸ”¬ Core Concepts Explained

### 1. ğŸ§© Layers and Neurons

Neural networks are composed of **layers** containing **neurons** (also called nodes or units). Think of neurons as mathematical functions that:
- Receive inputs from previous layer
- Apply weights and biases
- Pass result through activation function

#### Dense Layer Mathematics

For a dense (fully connected) layer:

```
Output = Input Ã— Weights + Bias
y = Xw + b
```

Where:
- `X` is input matrix (batch_size Ã— input_features)
- `w` is weight matrix (input_features Ã— neurons)
- `b` is bias vector (1 Ã— neurons)
- `y` is output matrix (batch_size Ã— neurons)

**Implementation Insight:**
```python
class DenseLayer:
    def __init__(self, n_inputs, n_neurons):
        # Xavier initialization for better convergence
        self.weights = np.random.randn(n_inputs, n_neurons) * 0.01
        self.biases = np.zeros((1, n_neurons))
    
    def forward(self, inputs):
        self.output = np.dot(inputs, self.weights) + self.biases
        return self.output
```

### 2. âš¡ Activation Functions

Activation functions introduce **non-linearity** into the network, enabling it to learn complex patterns.

#### ReLU (Rectified Linear Unit)
```
f(x) = max(0, x)
f'(x) = 1 if x > 0, else 0
```

**Why ReLU?**
- Solves vanishing gradient problem
- Computationally efficient
- Sparse activation (many zeros)

#### Sigmoid
```
f(x) = 1 / (1 + e^(-x))
f'(x) = f(x) Ã— (1 - f(x))
```

#### Softmax (for multi-class classification)
```
f(xi) = e^xi / Î£(e^xj) for j=1 to n
```

### 3. ğŸ“Š Loss Functions

Loss functions measure how "wrong" our predictions are.

#### Categorical Cross-Entropy
For multi-class classification:
```
L = -Î£(yi Ã— log(Å·i))
```

Where:
- `yi` is true label (one-hot encoded)
- `Å·i` is predicted probability

#### Binary Cross-Entropy
For binary classification:
```
L = -(yÃ—log(Å·) + (1-y)Ã—log(1-Å·))
```

## ğŸ¯ **4. Backpropagation: The Heart of Learning**

Backpropagation is the **chain rule of calculus** applied to neural networks. It's how networks learn by computing gradients and updating parameters.

### ğŸ”— The Chain Rule Foundation

The chain rule states that for composite functions:
```
âˆ‚f(g(x))/âˆ‚x = âˆ‚f/âˆ‚g Ã— âˆ‚g/âˆ‚x
```

### ğŸ§® Mathematical Derivation

Consider a simple network: Input â†’ Dense Layer â†’ Activation â†’ Loss

#### Forward Pass:
1. **Dense Layer**: `z = Xw + b`
2. **Activation**: `a = f(z)` 
3. **Loss**: `L = Loss(a, y_true)`

#### Backward Pass (Chain Rule Application):

**Step 1: Loss Gradient**
```
âˆ‚L/âˆ‚a = gradient of loss w.r.t. activation output
```

**Step 2: Activation Gradient**
```
âˆ‚L/âˆ‚z = âˆ‚L/âˆ‚a Ã— âˆ‚a/âˆ‚z
```

**Step 3: Dense Layer Gradients**

For weights:
```
âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚z Ã— âˆ‚z/âˆ‚w = âˆ‚L/âˆ‚z Ã— X^T
```

For biases:
```
âˆ‚L/âˆ‚b = âˆ‚L/âˆ‚z Ã— âˆ‚z/âˆ‚b = âˆ‚L/âˆ‚z
```

For inputs (to pass to previous layer):
```
âˆ‚L/âˆ‚X = âˆ‚L/âˆ‚z Ã— âˆ‚z/âˆ‚X = âˆ‚L/âˆ‚z Ã— w^T
```

### ğŸ”„ Implementation Deep Dive

```python
def backward(self, dvalues):
    # dvalues = âˆ‚L/âˆ‚z (gradient from next layer)
    
    # Gradient w.r.t. weights: âˆ‚L/âˆ‚w = X^T Ã— âˆ‚L/âˆ‚z
    self.dweights = np.dot(self.inputs.T, dvalues)
    
    # Gradient w.r.t. biases: âˆ‚L/âˆ‚b = sum(âˆ‚L/âˆ‚z)
    self.dbiases = np.sum(dvalues, axis=0, keepdims=True)
    
    # Gradient w.r.t. inputs: âˆ‚L/âˆ‚X = âˆ‚L/âˆ‚z Ã— w^T
    self.dinputs = np.dot(dvalues, self.weights.T)
```

### ğŸŒŠ Gradient Flow Visualization

```
Loss â†â”€â”€ Softmax â†â”€â”€ Dense3 â†â”€â”€ ReLU â†â”€â”€ Dense2 â†â”€â”€ ReLU â†â”€â”€ Dense1 â†â”€â”€ Input
 â†“         â†“          â†“         â†“         â†“         â†“         â†“
âˆ‚L/âˆ‚L   âˆ‚L/âˆ‚a3    âˆ‚L/âˆ‚z3    âˆ‚L/âˆ‚a2    âˆ‚L/âˆ‚z2    âˆ‚L/âˆ‚a1    âˆ‚L/âˆ‚z1
```

Each arrow represents the chain rule multiplication!

### 5. ğŸš€ Optimizers

Optimizers use gradients to update network parameters.

#### Stochastic Gradient Descent (SGD)
```
w_new = w_old - learning_rate Ã— âˆ‚L/âˆ‚w
b_new = b_old - learning_rate Ã— âˆ‚L/âˆ‚b
```

**Implementation:**
```python
class Optimizer_SGD:
    def __init__(self, learning_rate=1.0):
        self.learning_rate = learning_rate
    
    def update_params(self, layer):
        layer.weights -= self.learning_rate * layer.dweights
        layer.biases -= self.learning_rate * layer.dbiases
```

### 6. ğŸ”„ Training Loop: The Complete Cycle

The training process consists of two main phases:

#### Forward Pass ğŸ”„
1. **Input Processing**: Feed data through network
2. **Layer Computation**: Each layer transforms input
3. **Prediction**: Final layer outputs predictions
4. **Loss Calculation**: Compare predictions with true labels

#### Backward Pass â¬…ï¸
1. **Loss Gradient**: Compute âˆ‚L/âˆ‚output
2. **Backpropagate**: Apply chain rule through each layer
3. **Gradient Computation**: Calculate âˆ‚L/âˆ‚weights and âˆ‚L/âˆ‚biases
4. **Parameter Update**: Use optimizer to update weights

```python
# Training Loop Example
for epoch in range(epochs):
    # Forward Pass
    output = model.forward(X_train)
    loss = loss_function.calculate(output, y_train)
    
    # Backward Pass
    model.backward(output, y_train)
    
    # Update Parameters
    for layer in model.layers:
        if hasattr(layer, 'weights'):
            optimizer.update_params(layer)
```

## ğŸš€ Quick Start

```python
from layer.connect_layers import DenseLayer
from multi_activation.activation import Activation_ReLU, Activation_Softmax
from losses.loss import Loss_CategoricalCrossentropy
from model.main_model import Model, Optimizer_SGD

# Create model
model = Model()
model.add(DenseLayer(784, 128))  # Input layer
model.add(Activation_ReLU())
model.add(DenseLayer(128, 64))   # Hidden layer
model.add(Activation_ReLU())
model.add(DenseLayer(64, 10))    # Output layer
model.add(Activation_Softmax())

# Set loss and optimizer
model.loss = Loss_CategoricalCrossentropy()
optimizer = Optimizer_SGD(learning_rate=0.01)

# Training loop
for epoch in range(1000):
    output = model.forward(X_train)
    loss = model.loss.calculate(output, y_train)
    model.backward(output, y_train)
    
    for layer in model.layers:
        if hasattr(layer, 'weights'):
            optimizer.update_params(layer)
```

## ğŸ“ Key Learning Outcomes

- âœ… **Mathematical Foundation**: Deep understanding of linear algebra in neural networks
- âœ… **Backpropagation Mastery**: Complete grasp of gradient computation via chain rule
- âœ… **Implementation Skills**: Building neural networks from mathematical principles
- âœ… **Debugging Intuition**: Understanding what happens inside the "black box"

## ğŸ”¬ Advanced Topics Covered

- Gradient flow and vanishing gradients
- Weight initialization strategies
- Numerical stability in computations
- Batch processing and vectorization

## ğŸ“š Mathematical References

- **Chain Rule**: The foundation of backpropagation
- **Matrix Calculus**: Essential for efficient gradient computation
- **Probability Theory**: Understanding loss functions and predictions
- **Optimization Theory**: Gradient descent and convergence

---

*Built with â¤ï¸ and lots of â˜• to demystify the beautiful mathematics behind deep learning.*
